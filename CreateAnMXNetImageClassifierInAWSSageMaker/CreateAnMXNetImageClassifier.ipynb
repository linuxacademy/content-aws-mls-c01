{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A Cloud Guru](acg_logo.png)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>MXNet Imgage Classification</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sorting Lego bricks](./lego.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Lego Brick Sorting</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frameworks\n",
    "For this lab, we will be using Apache MXNet to build and train a model to classify images, and specifically take advantage of the Gluon API provided with MXNet to make that process really easy.\n",
    "\n",
    "## MXNet\n",
    "\n",
    "A flexible and efficient library for deep learning.\n",
    "\n",
    "- MXNet provides optimized numerical computation for GPUs and distributed ecosystems, from the comfort of high-level environments like Python and R.\n",
    "- MXNet automates common workflows, so standard neural networks can be expressed concisely in just a few lines of code.\n",
    "\n",
    "_(Source: https://mxnet.apache.org/)_\n",
    "\n",
    "## Gluon\n",
    "\n",
    "Based on the the Gluon API specification, the Gluon library in Apache MXNet provides a clear, concise, and simple API for deep learning. It provides basic building blocks for neural networks that make it easy to prototype, build, and train deep learning models without sacrificing training speed. Install a recent version of MXNet to get access to Gluon.\n",
    "\n",
    "_(Source: [AWS Blog](https://aws.amazon.com/blogs/machine-learning/introducing-gluon-an-easy-to-use-programming-interface-for-flexible-deep-learning/))_\n",
    "\n",
    "\n",
    "# Scenario\n",
    "\n",
    "We have bricks. Lots of bricks. LEGO bricks, that is. And we need to sort them.\n",
    "\n",
    "We also have a collection of photos of various LEGO bricks from different angles. We have 600 photos (which probably took us more time to collect than sorting the current bricks) and they are all labeled with the brick type.\n",
    "\n",
    "Each photo has been processed. This involved increasing the contrast, sharpening, removing the color, inverting the colors, and reducing the size.\n",
    "\n",
    "|![Sample LEGO brick photo](./sample-before.png)|![Sample LEGO brick photo](./sample-after.png)|\n",
    "|----------------------------------------|----------------------------------------|\n",
    "| Sample before processing                | Sample after processing                |\n",
    "\n",
    "In addition to this, we stored all the images into data arrays for easier loading into the notebook. These are stored in the `lego-simple-mx-train` and `lego-simple-mx-test` files.\n",
    "\n",
    "We need to create a simple, deep learning, neural network classifier model. We will train the model using the photo data and see if it correctly predicts the type of a brick from a supplied test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use This Lab\n",
    "\n",
    "All of the code is provided for you in this lab as our solution to the tasks presented. You could simply execute the notebook to get a result, but that's not really very hands-on and it won't teach you anything but how to execute cells in a Jupyter notebook. To get the most from this lab, you should understand what the code in each cell is trying to accomplish, and then take the time to experiment: make changes, break it, fix it, and learn! You can always pull the code down again to get a clean copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from mxnet import nd, gluon, autograd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a fixed random seed for reproducibility\n",
    "mx.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, lets take a moment to set the processor type MXNet will use. This Juypter Notebook server doesn't have access to GPU's and we let MXNet discover that here. That will be okay for what we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset created from a set of photos of LEGO bricks. In total we have 2 sets of data saved to files as NDArrays.\n",
    "\n",
    "1. __lego-simple-mx-train__ - _Training images and labels combined, around 80% of the data collected._\n",
    "2. __lego-simple-mx-test__ - _Testing or validation images and labels combined, around 20% of the data collected._\n",
    "\n",
    "First we load the data into runtime arrays. ```Pickle``` has been used to create these object files, so we use ```pickle``` to load them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the files:\n",
    "train_fh = open('lego-simple-mx-train', 'rb')\n",
    "test_fh = open('lego-simple-mx-test', 'rb')\n",
    "\n",
    "# Use pickle to load files into runtime objects:\n",
    "train_data = pickle.load(train_fh)\n",
    "test_data = pickle.load(test_fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label data we loaded are integer values (1,2,3). We want human names for the data classes we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For humans:\n",
    "class_names = ['2x3 Brick', '2x2 Brick', '1x3 Brick', '2x1 Brick', '1x1 Brick', \n",
    "               '2x2 Macaroni', '2x2 Curved End', 'Cog 16 Tooth', '1x2 Handles', '1x2 Grill']\n",
    "\n",
    "# Or the real LEGO codes:\n",
    "# class_names = ['3002', '3003', '3622', '3004', '3005', '3063', '47457', '94925', '3839a', '2412b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to MXNet Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the data loaded into NDArrays. Now we transfer the data into MXNet tensors.\n",
    "\n",
    "Tensors act like arrays but with extra capability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.13, 0.31)])\n",
    "\n",
    "train_data = train_data.transform_first(transformer)\n",
    "test_data = test_data.transform_first(transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one of the images loaded with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_no = 0\n",
    "\n",
    "images_data, label_data = train_data[train_image_no]\n",
    "plt.figure()\n",
    "plt.imshow(images_data.reshape((48,48)).asnumpy())\n",
    "plt.colorbar()\n",
    "plt.xlabel(class_names[label_data])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some more of the data and make the formating a little nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(20):\n",
    "    images_data, label_data = train_data[i]\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(images_data.reshape((48,48)).asnumpy(), cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[label_data])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is loaded, so let's start training. First, we need to create a model. With MXNet we often call the model object ```net```. We are creating an artificial neural network. It has 4 layers:\n",
    "\n",
    "1. The input layer with enough nodes for our image data.\n",
    "2. A hidden layer with 128 nodes and ReLU activation.\n",
    "3. A hidden layer with 64 nodes and ReLU activation.\n",
    "4. An output layer with 10 nodes, one for each of the classes we want to identify.\n",
    "\n",
    "Each layer is densely connected, meaning that each neuron in one layer is connected to every neuron in the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.HybridSequential(prefix='MLP_')\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(128, activation='relu'),\n",
    "        nn.Dense(64, activation='relu'),\n",
    "        nn.Dense(10, activation=None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MXNet Gluon provides data loaders we can use to simplify the loading of data when training our model. Let's set them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 34\n",
    "train_loader = mx.gluon.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the model. Note we pass in the variable holding the processor type here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gluon provides a trainer object to maintain the state of the training. We create it here, and use it in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(\n",
    "    params=net.collect_params(),\n",
    "    optimizer='sgd',\n",
    "    optimizer_params={'learning_rate': 0.04},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready to train. First, we define the metric to use while we train and the loss function to use. Gluon provides a softmax loss function, so we just use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = mx.metric.Accuracy()\n",
    "loss_function = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train. We could write the following code into a ```fit``` function, but this inline code does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "history = []\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        # Possibly copy inputs and labels to the GPU\n",
    "        inputs = inputs.as_in_context(ctx)\n",
    "        labels = labels.as_in_context(ctx)\n",
    "\n",
    "        # Forward pass\n",
    "        with autograd.record():\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        metric.update(labels, outputs)\n",
    "\n",
    "        # Update\n",
    "        trainer.step(batch_size=inputs.shape[0])\n",
    "\n",
    "    # Print the evaluation metric and reset it for the next epoch\n",
    "    name, acc = metric.get()\n",
    "    history.insert(epoch,acc)\n",
    "    print('.', end='')\n",
    "    metric.reset()\n",
    "\n",
    "print('[Done]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training loop we collected accuracy data in each epoch. Let's graph this data to get a sense of how the training went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the test data to perform an accuracy measurement. Is the accuracy with the testing data much lower than the end of training? If so our model might be overfit.  \n",
    "\n",
    "We use the Gluon data loader again, this time with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = mx.gluon.data.DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And measure the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = mx.metric.Accuracy()\n",
    "for inputs, labels in test_loader:\n",
    "    # Possibly copy inputs and labels to the GPU\n",
    "    inputs = inputs.as_in_context(ctx)\n",
    "    labels = labels.as_in_context(ctx)\n",
    "    metric.update(labels, net(inputs))\n",
    "metric_name, metric_value = metric.get()\n",
    "print(f'Validation: {metric_name} = {metric_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Test the Model\n",
    "\n",
    "In order to make our tests look good, we define a couple of functions to dispaly the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the image:\n",
    "def plot_image(predictions_array, true_label, img):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    #Image data is currently a flat array. Convert to matrix for display\n",
    "    plt.imshow(img.reshape((48,48)).asnumpy(), cmap=plt.cm.binary)\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    probability = 100 * np.max(predictions_array)\n",
    "    color = 'green' if predicted_label == true_label else 'red'\n",
    "    # Print a label with 'predicted class' 'actual class'\n",
    "    plt.xlabel(f\"{class_names[predicted_label]} ({true_label} - {class_names[true_label]})\",\n",
    "                                color=color)\n",
    "\n",
    "# Function to display the prediction results in a graph:\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    plot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    plot[predicted_label].set_color('red')\n",
    "    plot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Prediction\n",
    "\n",
    "Let's test out model. Choose one of the images from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image_number = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image, prediction_label = test_data[prediction_image_number]\n",
    "predictions_single = net(prediction_image)\n",
    "predictions_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a bar chart using the helper function. This gives us a sense of how well the model classified this image. The predicted label will be red if it is different than the actual label. The actual label will be green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_array(predictions_single[0].asnumpy(), prediction_label)\n",
    "plt.xticks(range(10), class_names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And which block should we have found? In other words, did we get it right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(predictions_single[0].asnumpy(), prediction_label, prediction_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Prediction\n",
    "\n",
    "Now lets get prediction values for **all** the test images we have. This time we don't use a data loader, we just iterate through the raw test image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "test_labels = []\n",
    "\n",
    "for i in test_data:\n",
    "    pred_image, pred_label = i\n",
    "    p = net(pred_image)\n",
    "    predictions.append(p)\n",
    "    test_labels.append(pred_label)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use our helper functions to summarize the first 16 images in our test data. How did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_rows = 8\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(15, 16))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(predictions[i].asnumpy(), test_data[i][1], test_data[i][0])\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(predictions[i][0].asnumpy(), test_data[i][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "I got an accuracy of about 95%. Your model might be slightly higher or lower. For your actual problem (sorting the blocks), is approximately 95% accuracy good enough for you? Are you willing to have about 1 in 20 of your bricks in the wrong place for the advantage of not having to manually decide which type of brick you are sorting? That's up to you! You can also analyze which bricks the model is consistently getting wrong and reorganize those bins yourself once the model is finished. Machine learning is just one tool and one option.\n",
    "\n",
    "Use the rest of your lab time to experiment with the model architecture to see if you can improve on your current accuracy. Try using another random seed. You can also change the number of training epochs, but be careful not to overfit your model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
