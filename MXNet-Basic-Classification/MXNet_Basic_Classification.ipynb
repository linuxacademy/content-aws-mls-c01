{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Linux Academy](la-logo.png)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>MXNet Basic Classification</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sorting Lego bricks](./lego.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Lego Brick Sorting</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this Linux Academy hands-on lab we take an introductory look at __TensorFlow__ (with __Keras__) and use it to make a simple artificial neural network.\n",
    "\n",
    "## MXNet\n",
    "\n",
    "A flexible and efficient library for deep learning.\n",
    "\n",
    "- MXNet provides optimized numerical computation for GPUs and distributed ecosystems, from the comfort of high-level environments like Python and R.\n",
    "- MXNet automates common workflows, so standard neural networks can be expressed concisely in just a few lines of code.\n",
    "\n",
    "_(Source: https://mxnet.apache.org/)_\n",
    "\n",
    "## Gluon\n",
    "\n",
    "Based on the the Gluon API specification, the new Gluon library in Apache MXNet provides a clear, concise, and simple API for deep learning. It makes it easy to prototype, build, and train deep learning models without sacrificing training speed. Install the latest version of MXNet to get access to Gluon.\n",
    "\n",
    "_(Source: https://mxnet.apache.org/versions/master/gluon/index.html)_\n",
    "\n",
    "\n",
    "# Scenario\n",
    "\n",
    "We have bricks, lots of brick. Lego bricks that is. And we need to sort them.\n",
    "\n",
    "We have a collection of photos of different Lego bricks from different angles. We have 1800 photos (really we do) and they are all labeled with the brick name.\n",
    "\n",
    "Each photo has been processed. This involved increasing the contrast, sharpening, removing the color, inverting the colors, and reducing the size.\n",
    "\n",
    "|![Sample Lego brick photo](./sample-before.png)|![Sample Lego brick photo](./sample-after.png)|\n",
    "|----------------------------------------|----------------------------------------|\n",
    "| Sample before processing                | Sample after processing                |\n",
    "\n",
    "In addition to this, we loaded all the images into a single data array for easier loading into the algorithm.  If you're interested in how these images were collected and processed, contact me through the Linux Academy Community Slack: ```@mike chambers```.\n",
    "\n",
    "We need to create a simple, deep learning, neural network classifier model. We will train the model using the photo data and see if it correctly predicts or infers the type of a brick from a supplied test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use This Lab\n",
    "\n",
    "This is a follow-along lab. That is to say the code in this Jupyter Notebook should be complete, and you could simply execute the notebook to get a result. However, watch along with the video to learn more about what is happening in the code and then take the time to experiment with the code; make changes, break it, fix it, and learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from mxnet import nd, gluon, autograd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a fixed random seed for reproducibility\n",
    "mx.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, lets take a moment to set the processor type MXNet will use. This Juypter Notebook server doesn't have access to GPU's and we let MXNet discover that here. That will be okay for what we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Load the data [numpy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset created from a set of photos of Lego bricks. In total we have 2 sets of data saved to files as NDArrays.\n",
    "\n",
    "1. __lego-simple-mx-train__ - _Training images and labels combined, around 80% of the data collected._\n",
    "2. __lego-simple-mx-test__ - _Testing or validation images and labels combined, around 20% of the data collected._\n",
    "\n",
    "First we load the data into runtime arrays. ```Pickle``` has been used to create these object files, so we use ```pickle``` to load them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the files:\n",
    "train_fh = open('lego-simple-mx-train', 'rb')\n",
    "test_fh = open('lego-simple-mx-test', 'rb')\n",
    "\n",
    "# Use pickle to load files into runtime objects:\n",
    "train_data = pickle.load(train_fh)\n",
    "test_data = pickle.load(test_fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label data we loaded are integer values (1,2,3). We want human names for the data classes we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For humans:\n",
    "class_names = ['2x3 Brick', '2x2 Brick', '1x3 Brick', '2x1 Brick', '1x1 Brick', '2x2 Macaroni', '2x2 Curved End', 'Cog 16 Tooth', '1x2 Handles', '1x2 Grill']\n",
    "\n",
    "# Or the real Lego codes:\n",
    "# class_names = ['3002', '3003', '3622', '3004', '3005', '3063', '47457', '94925', '3839a', '2412b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to MXNet Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the data loaded into NDArrays. Now we transfer the data into MXNet tensors.\n",
    "\n",
    "Tensors act like arrays but with extra capability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.13, 0.31)])\n",
    "\n",
    "train_data = train_data.transform_first(transformer)\n",
    "test_data = test_data.transform_first(transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is loaded but it's nice to see it. Let's take a look at one of the images loaded with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_no = 0\n",
    "\n",
    "images_data, label_data = train_data[train_image_no]\n",
    "plt.figure()\n",
    "plt.imshow(images_data.reshape((48,48)).asnumpy())\n",
    "plt.colorbar()\n",
    "plt.xlabel(class_names[label_data])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some more of the data and make the formating a little nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(20):\n",
    "    images_data, label_data = train_data[i]\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(images_data.reshape((48,48)).asnumpy(), cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[label_data])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Training [MXNet Gluon]Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is loaded, so let's start training. First, we need to create a model. With MXNet we often call the model object ```net```. We are creating an artificial neural network. It has 4 layers:\n",
    "\n",
    "1. The input layer with enough nodes for our image data.\n",
    "2. A hidden layer with 128 nodes and ReLU activation.\n",
    "3. A hidden layer with 64 nodes and ReLU activation.\n",
    "4. An output layer with 10 nodes, one for each of the classes we want to identify.\n",
    "\n",
    "Each layer is densely connected, meaning that each neuron in one layer is connected to every neuron in the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.HybridSequential(prefix='MLP_')\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(128, activation='relu'),\n",
    "        nn.Dense(64, activation='relu'),\n",
    "        nn.Dense(10, activation=None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MXNet Gluon provides data loaders we can use to simplify the loading of data when training our model. Let's set them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 34\n",
    "train_loader = mx.gluon.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the model. Note we pass in the variable holding the processor type here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gluon provides a trainer object to maintain the state of the training. We create it here, and use it in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(\n",
    "    params=net.collect_params(),\n",
    "    optimizer='sgd',\n",
    "    optimizer_params={'learning_rate': 0.04},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready to train. First, we define the metric to use while we train and the loss function to use. Gluon provides a softmax loss function, so we just use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = mx.metric.Accuracy()\n",
    "loss_function = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train. We could write the following code into a ```fit``` function, but this inline code does the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "history = []\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        # Possibly copy inputs and labels to the GPU\n",
    "        inputs = inputs.as_in_context(ctx)\n",
    "        labels = labels.as_in_context(ctx)\n",
    "\n",
    "        # Forward pass\n",
    "        with autograd.record():\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        metric.update(labels, outputs)\n",
    "\n",
    "        # Update\n",
    "        trainer.step(batch_size=inputs.shape[0])\n",
    "\n",
    "    # Print the evaluation metric and reset it for the next epoch\n",
    "    name, acc = metric.get()\n",
    "    history.insert(epoch,acc)\n",
    "    print('.', end='')\n",
    "    metric.reset()\n",
    "\n",
    "print('[Done]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training loop we collected accuracy data in each epoch. Let's graph this data to get a sense of how the training went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the test data to perform an accuracy measurement. Is the accuracy with the testing data much lower than the end of training? If so our model might be overfit.  \n",
    "\n",
    "We use the Gluon data loader again, this time with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = mx.gluon.data.DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And measure the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = mx.metric.Accuracy()\n",
    "for inputs, labels in test_loader:\n",
    "    # Possibly copy inputs and labels to the GPU\n",
    "    inputs = inputs.as_in_context(ctx)\n",
    "    labels = labels.as_in_context(ctx)\n",
    "    metric.update(labels, net(inputs))\n",
    "print('Validaton: {} = {}'.format(*metric.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Test\n",
    "\n",
    "In order to make our tests look good, we define a couple of functions to dispaly the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the image:\n",
    "def plot_image(predictions_array, true_label, img):\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(img.reshape((48,48)).asnumpy(), cmap=plt.cm.binary)\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'green'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  # Print a label with 'predicted class', 'probability %', 'actual class'\n",
    "  plt.xlabel(\"{} [{:2.0f}] ({})\".format(class_names[predicted_label],\n",
    "                                np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "# Function to display the prediction results in a graph:\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  plot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  plot[predicted_label].set_color('red')\n",
    "  plot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Prediction\n",
    "\n",
    "Let's test out model. Choose one of the images from our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image_number = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image, prediction_label = test_data[prediction_image_number]\n",
    "predictions_single = net(prediction_image)\n",
    "predictions_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display those results with our function defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_array(predictions_single[0].asnumpy(), prediction_label)\n",
    "plt.xticks(range(10), class_names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And which block should we have found? In other words, did we get it right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(predictions_single[0].asnumpy(), prediction_label, prediction_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Prediction\n",
    "\n",
    "Now lets get prediction values for **all** the test images we have. This time we don't use a data loader, we just iterate through the raw test image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "test_labels = []\n",
    "\n",
    "for i in test_data:\n",
    "    pred_image, pred_label = i\n",
    "    p = net(pred_image)\n",
    "    predictions.append(p)\n",
    "    test_labels.append(pred_label)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use our helper functions to summarize the first 16 images in our test data. How did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 8\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(15, 16))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(predictions[i].asnumpy(), test_data[i][1], test_data[i][0])\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(predictions[i][0].asnumpy(), test_data[i][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the end of this Linux Academy hands-on lab. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
