{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Linux Academy](la-logo.png)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>PyTorch Simple CNN</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sorting Lego bricks](./lego.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Lego Brick Sorting</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this Linux Academy hands-on lab, we take an introductory look at __PyTorch__ (with `PyTorch.nn`) and use it to make a simple convolutional neural network.\n",
    "\n",
    "## PyTorch\n",
    "\n",
    "![PyTorch Logo](./pytorch-logo.png)\n",
    "\n",
    "PyTorch is an open source, deep learning platform that provides a seamless path from research prototyping to production deployment.\n",
    "\n",
    "_(Source: https://pytorch.org)_\n",
    "\n",
    "PyTorch is very powerful, and with great power... comes a steep learning curve. To help with this and other optimizations, ```pytorch.nn``` is a set of Modules (with a capital M; these are not the same as Python modules). They have prewritten, optimized code for many common ML tasks.\n",
    "\n",
    "In this Linux Academy hands-on lab we use some of the ```pytorch.nn``` Modules to get us going faster.\n",
    "\n",
    "\n",
    "# Scenario\n",
    "\n",
    "We have bricks, lots of bricks, Lego bricks that is. And we need to get them sorted.\n",
    "\n",
    "We have a collection of photos of different Lego bricks from different angles. We have 600 photos (really we do) and they are all labeled with the brick name.\n",
    "\n",
    "Each photo has been processed by increasing the contrast, sharpening, removing the color, inverting the colors, and reducing its size.\n",
    "\n",
    "|![Sample Lego brick photo](./sample-before.png)|![Sample Lego brick photo](./sample-after.png)|\n",
    "|----------------------------------------|----------------------------------------|\n",
    "| Sample before processing                | Sample after processing                |\n",
    "\n",
    "In addition to this, we loaded all the images into a single data array for easier loading into an algorithm. If you're interested in how these images were collected and processed contact me through the Linux Academy Community Slack: ```@mike chambers```.\n",
    "\n",
    "We're going to create a simple, deep learning, neural network classifier model. We will train the model using the photo data and see if it correctly predicts or infers the type of a brick from a supplied test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use This Lab\n",
    "\n",
    "This is a follow-along lab. That is to say the code in this Jupyter Notebook should be complete, and you could simply execute the notebook to get a result. However, watch along with the video to learn more about what is happening in the code and then take the time to experiment with the code; make changes, break it, fix it, and learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, let's take a moment to set the processor type that PyTorch will be using. PyTorch is optimized for running on GPUs. Since this Juypter Notebook server doesn't have access to GPUs, we need to tell PyTorch to use the CPU instead. That will be ok for what we are doing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [NumPy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data. This lab includes four files containing the data we want:\n",
    "\n",
    "1. `lego-simple-lin-train-images.npy` - Training images, around 80% of the data collected.\n",
    "2. `lego-simple-lin-train-labels.npy` - A list of integer labels that identifiy the classes of the training images.\n",
    "3. `lego-simple-lin-test-images.npy`  - Testing images, around 20% of the data collected.\n",
    "4. `lego-simple-lin-test-labels.npy`  - A list of integer labels that identifiy the classes of the testing images.\n",
    "\n",
    "The data is stored in NumPy file format. We convert it to PyTorch tensors later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('lego-simple-lin-train-images.npy').astype(np.float32)\n",
    "y_train = np.load('lego-simple-lin-train-labels.npy')\n",
    "x_valid = np.load('lego-simple-lin-test-images.npy').astype(np.float32)\n",
    "y_valid = np.load('lego-simple-lin-test-labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label data we loaded are integer values (1,2,3). Let's get some human names for the data classes we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For humans:\n",
    "class_names = ['2x3 Brick', '2x2 Brick', '1x3 Brick', '2x1 Brick', '1x1 Brick', '2x2 Macaroni', '2x2 Curved End', 'Cog 16 Tooth', '1x2 Handles', '1x2 Grill']\n",
    "\n",
    "# Or the real Lego codes:\n",
    "# class_names = ['3002', '3003', '3622', '3004', '3005', '3063', '47457', '94925', '3839a', '2412b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images we are using are 48 by 48 pixels. We set that here as a convenience, so if we want to try other images with this code, we change these values. For now, this works as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 48\n",
    "image_height = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading data, especially image data, it's good to visialize it. If nothing else, it helps us see we didn't mangle the data.\n",
    "\n",
    "The following is a helper function to plot the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(data, label):\n",
    "    plt.figure()\n",
    "    plt.imshow(data.reshape((image_width, image_height)))\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(class_names[label])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we choose an image from our set and send it to the plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_number = 0\n",
    "plot_img(x_train[img_number], y_train[img_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [PyTorch]\n",
    "\n",
    "We have the data loaded into NumPy arrays. Now we transfer the data into PyTourch tensors.\n",
    "\n",
    "Tensors act like arrays but with extra capability. When we create the tensors, we pass the ```device``` object we created so PyTorch configures them for the appropriate processor architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train).to(device)\n",
    "y_train = torch.tensor(y_train).to(device)\n",
    "x_valid = torch.tensor(x_valid).to(device)\n",
    "y_valid = torch.tensor(y_valid).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's take a quick look at the data. PyTorch tensors work a lot like NumPy arrays. We can even use ```.shape``` to describe the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the data itself, or at least a summary of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create the model, we set some hyperparameters that impact how the model learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 20\n",
    "batch_size = 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the hyperparameters set, we can create some dataloaders. These dataloaders are `PyTorch.nn` objects that help with loading data into the model as it trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section of code creates the model itself. We are using the sequential model of `PyTorch.nn` to allow us to create our model quickly and logically.\n",
    "\n",
    "We create `TorchModule` as a wrapper for a preprocessing layer and our output layer. We could use the same structure to make a layer in our network be anything we want.\n",
    "\n",
    "The model itself is sequentially defined as a convolutional neural network (CNN). Each layer after the first is defined as the number of nodes in the previous layer plus the number of nodes in the current layer. Consider the following:\n",
    "\n",
    "```\n",
    "nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1),\n",
    "nn.ReLU(),\n",
    "```\n",
    "\n",
    "This defines a two-dimentional CNN layer connecting from 32 nodes in the previous layer, to 16 modes in this layer.\n",
    "\n",
    "* ```kernel_size``` - The size of the 'kernel' that convolves over the image.\n",
    "* ```stride``` - The step size the 'kernel' uses when convolving. \n",
    "* ```padding``` - A padding applied to the image so we don't lose information from the edge.\n",
    "\n",
    "Finally, in the code block above, we add a rectified linear unit (ReLU) as an activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModule(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, image_width, image_height).to(device)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    TorchModule(preprocess),\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    TorchModule(lambda x: x.view(x.size(0), -1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define one of the built-in optimization algorithms to use and a loss function to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, we define some functions to help us with the tasks at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_batch calculates the loss and is intended to be used during training.\n",
    "# If no optimizer is being passed then we are in a validation phase and we miss it out.\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "# We are writing our own fit function.\n",
    "# You can see the structure of the function going through the steps required to train.\n",
    "# As we progress through the epochs we store the loss value so that we can summarise the \n",
    "# training process in a graph later.\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # First we train:\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        # Then we evaluate:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        \n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        history.insert(epoch,val_loss)\n",
    "        print('.', end='')\n",
    "        \n",
    "    print('[Done]')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set it all in motion. We train and then plot a graph of the loss function over the epochs. The loss function looks at the model prediction and the actual labeled data. It calculates the difference or loss. We want the loss to get lower as the training progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the model. Choose one of the iamges from our validation set. _(Yes, you're right, we shouldn't test with an image from our validation set, but if it doesn't get this right, then we're in trouble.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_test = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, what is this image? Let's check to see what the prediction should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(x_valid[img_to_test].numpy(), y_valid[img_to_test].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make the prediction. Did the model get it right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model(x_valid[img_to_test])\n",
    "\n",
    "prediction = torch.argmax(p)\n",
    "class_label = class_names[prediction.numpy()]\n",
    "\n",
    "prediction, class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're happy with the model up until this point, let's throw a lot of data at it. Let's make predictions from the whole validation set.  \n",
    "\n",
    "To help display the output, here are a couple of helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(predictions_array, true_label, img):\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(img.reshape((image_width, image_height)), cmap=plt.cm.binary)\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    # Print a label with 'predicted class', 'probability %', 'actual class'\n",
    "    plt.xlabel(\"{} [{:2.0f}] ({})\".format(class_names[predicted_label],\n",
    "                                  np.max(predictions_array),\n",
    "                                  class_names[true_label]),\n",
    "                                  color=color)\n",
    "\n",
    "# Function to display the prediction results in a graph:\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  plot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  plot[predicted_label].set_color('red')\n",
    "  plot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions from all the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 8\n",
    "num_cols = 2\n",
    "\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(15, 16))\n",
    "\n",
    "for i in range(num_images):\n",
    "    ipred = predictions[i].detach().numpy()\n",
    "    iimg = x_train[i].detach().numpy()\n",
    "    ilab = y_valid[i].detach().numpy()\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(ipred, ilab, iimg)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(ipred, ilab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the end of this Linux Academy hands-on lab. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
